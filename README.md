# ğŸ”® DejaView
### Near-Duplicate Image Detection System

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch">
  <img src="https://img.shields.io/badge/CLIP-OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white" alt="CLIP">
  <img src="https://img.shields.io/badge/DINOv2-Meta-0467DF?style=for-the-badge&logo=meta&logoColor=white" alt="DINOv2">
  <img src="https://img.shields.io/badge/FAISS-Facebook-4267B2?style=for-the-badge&logo=facebook&logoColor=white" alt="FAISS">
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit">
</p>

<p align="center">
  <i>"Maya represents the veil of illusion where one truth can take a thousand different forms."</i>
</p>

<p align="center">
  <b>DejaView</b> is a high-performance **Near-Duplicate Image Detection** system. It acts like the <b>Sudarshana Chakra</b>â€”cutting through the illusions of editing, compression, and manipulation to identify the original "soul" (the source image) within a vast sea of data.
</p>

---

## ğŸ¨ Visual Capability Showcase

DejaView goes beyond simple exact matching. It detects images even when they are heavily modified.

| **âœ‚ï¸ Cropped** | **ğŸ’§ Watermarked** | **ğŸ¨ Color Adjusted** |
|:---:|:---:|:---:|
| <img src="assets/examples/cropped.jpg" width="200" /> | <img src="assets/examples/watermark.jpg" width="200" /> | <img src="assets/examples/color.jpg" width="200" /> |
| *Detects partial content* | *Ignores overlays & text* | *Robust to filters & shifts* |

| **ğŸ“¦ Compressed** | **ğŸ”„ Resized** | **ğŸ–¼ï¸ Edited/Mixed** |
|:---:|:---:|:---:|
| <img src="assets/examples/compressed.jpg" width="200" /> | <img src="assets/examples/resized.jpg" width="200" /> | <img src="assets/examples/edited.jpg" width="200" /> |
| *Handling artifacts* | *Scale invariant* | *Semantic similarity* |

---

## ï¿½ The Detection Pipeline

This system uses a **multi-stage funnel** to balance extreme speed with high accuracy.

```mermaid
graph TD
    subgraph Input
    I[ğŸ“¥ Incoming Image]
    end

    subgraph "Stage 1: Fast Filtering"
    I -->|Pre-check| S{ğŸ¯ Structure Check}
    S --"Too Few Features"--> R[ğŸš« REJECTED]
    S --"Valid"--> H{ğŸ” Hash Check}
    end

    subgraph "Stage 2: Semantic Analysis"
    H --"Exact/Near Match"--> M[âœ… SIMILAR (Fast)]
    H --"No Match"--> D{ğŸ¦• DINOv2 Check}
    D --"High Similarity (>55%)"--> M2[âœ… SIMILAR (Robust)]
    D --"Ambiguous (20-55%)"--> C{ğŸ“ CLIP Check}
    end
    
    subgraph "Stage 3: Fallback"
    C --"Confirmed"--> M3[âœ… SIMILAR (Semantic)]
    C --"Low Score"--> U[âŒ UNIQUE]
    D --"Low Complexity"--> U
    end

    style I fill:#f9f,stroke:#333
    style M fill:#bfb,stroke:#333
    style M2 fill:#bfb,stroke:#333
    style M3 fill:#bfb,stroke:#333
    style U fill:#fbb,stroke:#333
    style R fill:#ccc,stroke:#333
```

---

## ğŸ“‹ Table of Contents

<details>
<summary><b>Click to expand</b></summary>

- [ğŸ¯ Problem Statement](#-problem-statement)
- [ğŸ’¡ Solution Overview](#-solution-overview)
- [ğŸ—ï¸ System Architecture](#ï¸-system-architecture)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ› ï¸ Installation](#ï¸-installation)
- [ğŸš€ Usage](#-usage)
- [ğŸ”¬ Technical Details](#-technical-details)

</details>

---

## ğŸ¯ Problem Statement

In the digital age, images are rarely unique. They are **resized**, **cropped**, **compressed**, and **edited**. 
Traditional hashing methods (MD5, SHA) fail instantly if a single pixel changes. 

**DejaView** solves this by using:
1.  **Perceptual Hashing (pHash)** for robust fingerprinting of visual structure.
2.  **Wavelet Hashing (wHash)** for frequency-domain comparison.
3.  **DINOv2 (Vision Transformer)** for understanding the *content* and *layout*, detecting objects even when cropped or shifted.
4.  **CLIP** for semantic backup when structural features are ambiguous.

---

## ğŸ—ï¸ System Architecture

```mermaid
flowchart LR
    User[ï¿½ User] --> UI[ğŸ–¥ï¸ Streamlit UI]
    UI --> API[ğŸ“¦ API Layer]
    
    subgraph Engine [âš™ï¸ Detection Engine]
        API --> PL[Pipeline Controller]
        
        PL -->|1. Check| ORB[ORB Feature Count]
        PL -->|2. Check| PH[pHash Index]
        PL -->|3. Check| WH[wHash Index]
        PL -->|4. Check| DINO[DINOv2 Embeddings]
        PL -->|5. Check| CLIP[CLIP Embeddings]
    end
    
    subgraph Data [ğŸ’¾ Vector Store]
        PH <--> IDX1[(Binary Index)]
        WH <--> IDX2[(Binary Index)]
        DINO <--> IDX3[(Dense Index)]
        CLIP <--> IDX4[(Dense Index)]
    end

    PL -->|Result| UI
```

---

## ğŸ“ Project Structure

```bash
DejaView/
â”œâ”€â”€ ğŸ“‚ src/                        # Source Code
â”‚   â”œâ”€â”€ ğŸ“‚ core/                   # ğŸ§  Brains (Pipeline, Index Management)
â”‚   â”œâ”€â”€ ğŸ“‚ models/                 # ğŸ¤– Models (DINO, CLIP, Pooling)
â”‚   â”œâ”€â”€ ğŸ“‚ utils/                  # ğŸ› ï¸ Tools (Hashing, FAISS, Verification)
â”‚   â””â”€â”€ ï¿½ config.py               # âš™ï¸ Configuration
â”‚
â”œâ”€â”€ ï¿½ assets/                     # ğŸ¨ Images & Examples
â”‚   â””â”€â”€ ï¿½ examples/               # (Used in this README)
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                    # âš¡ Automation
â”‚   â”œâ”€â”€ ğŸ“„ index_full_folder.py    # Batch Indexer
â”‚   â””â”€â”€ ğŸ“„ setup_models.py         # Model Downloader
â”‚
â”œâ”€â”€ ğŸ“‚ web/                        # ğŸŒ Frontend
â”‚   â””â”€â”€ ğŸ“„ app.py                  # Streamlit App
â”‚
â”œâ”€â”€ ğŸ“‚ data/                       # ğŸ’¾ Database (Local)
â”‚   â”œâ”€â”€ ğŸ“‚ images/                 # Image Store
â”‚   â”œâ”€â”€ ğŸ“‚ indices/                # FAISS Indices
â”‚   â””â”€â”€ ğŸ“‚ models/                 # Model Weights
â”‚
â””â”€â”€ ğŸ“„ run_dejaview.py             # ğŸš€ Entry Point
```

---

## ğŸ› ï¸ Installation

1.  **Clone & Setup**
    ```bash
    git clone https://github.com/your-username/DejaView.git
    cd DejaView
    pip install -r requirements.txt
    ```

2.  **Download Models**
    ```bash
    python -m scripts.setup_models
    ```

---

## ğŸ¬ Live Demo

See **DejaView** in action! Watch how it handles resizing, cropping, and edits in real-time.

<div align="center">
  <a href="https://www.youtube.com/watch?v=YOUR_VIDEO_ID_HERE">
    <img src="https://img.youtube.com/vi/YOUR_VIDEO_ID_HERE/maxresdefault.jpg" alt="Watch the Demo" width="100%">
  </a>
</div>

---

## ğŸš€ Usage

### 1. Start the UI
```bash
python run_dejaview.py
```
*Upload an image to see the pipeline in action.*

### 2. Batch Indexing
Index a folder of existing images to build your database:
```bash
python scripts/index_full_folder.py
```

---

## ğŸ”¬ Technical Deep Dive

### ğŸ§  GeM Pooling (Generalized Mean Pooling)
We rely on **GeM Pooling** for feature extraction. Unlike standard Global Average Pooling, GeM is a learnable parameter that focuses on "salient" features.

$$ \textbf{f} = \left( \frac{1}{|X|} \sum_{x \in X} x^p \right)^{\frac{1}{p}} $$

This makes our detection **robust to cropping**, as it aggregates features spatially rather than just taking a single class token.

### ğŸ“Š Thresholds
*   **Hash Match**: Distance â‰¤ 4 (Bits)
*   **DINO Match**: Similarity â‰¥ 55%
*   **CLIP Fallback**: Similarity â‰¥ 59% (Triggered if DINO is 20-55%)

---
<p align="center">Made with â¤ï¸ for the Community</p>