<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-blue?logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/CLIP-OpenAI-green?logo=openai&logoColor=white" alt="CLIP">
  <img src="https://img.shields.io/badge/FAISS-Facebook-orange?logo=facebook&logoColor=white" alt="FAISS">
  <img src="https://img.shields.io/badge/Streamlit-UI-red?logo=streamlit&logoColor=white" alt="Streamlit">
</p>

# ğŸ”® DejaView â€” Near-Duplicate Image Detection (NDID)

> *"Maya represents the veil of illusion where one truth can take a thousand different forms."*

**DejaView** is a high-performance Near-Duplicate Image Detection system that acts like the **Sudarshana Chakra**â€”a tool of ultimate discernment that cuts through the illusions of editing and compression to identify the original "soul" (the source image) within a vast sea of data.

---

## ğŸ“‹ Table of Contents

- [Problem Statement](#-problem-statement)
- [Solution Overview](#-solution-overview)
- [System Architecture](#-system-architecture)
- [Pipeline Workflow](#-pipeline-workflow)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [Technical Details](#-technical-details)
- [Evaluation Metrics](#-evaluation-metrics)
- [Datasets](#-datasets)

---

## ğŸ¯ Problem Statement

In modern digital platforms such as **social media**, **e-commerce**, **content hosting**, and **news aggregation systems**, millions of images are uploaded every day. A significant portion of these uploads are **duplicate or near-duplicate images**â€”the same image uploaded multiple times or slightly modified versions of an existing image.

### Challenges

Traditional systems struggle to automatically detect these duplicates when images are:

| Transformation | Description |
|----------------|-------------|
| ğŸ”„ **Resized** | Scaled up or down |
| âœ‚ï¸ **Cropped** | Portions removed |
| ğŸ“¦ **Compressed** | Quality reduced (JPEG artifacts) |
| ğŸ¨ **Color-adjusted** | Brightness, contrast, saturation changes |
| ğŸ’§ **Watermarked** | Text or logos overlaid |
| ğŸ–¼ï¸ **Slightly edited** | Minor retouching or filters |

### ğŸ–¼ï¸ Transformation Examples

DejaView can detect duplicates across all these transformations:

#### ğŸ”„ Resized (Scaled up or down)
| Original | Detection |
|:--------:|:---------:|
| ![Original](assets/examples/resized_original.png) | âœ… Detected |

---

#### âœ‚ï¸ Cropped (Portions removed)
| Original | Detection |
|:--------:|:---------:|
| ![Original](assets/examples/cropped_original.png) | âœ… Detected |


---

#### ğŸ“¦ Compressed (Quality reduced - JPEG artifacts)
| Original | Detection |
|:--------:|:---------:|
| ![Original](assets/examples/compressed_original.png) | âœ… Detected |


---

#### ğŸ¨ Color-adjusted (Brightness, contrast, saturation changes)
| Original | Detection |
|:--------:|:---------:|
| ![Original](assets/examples/color_original.png)| âœ… Detected |


---

#### ğŸ’§ Watermarked (Text or logos overlaid)
| Original | Detection |
|:--------:|:---------:|
| ![Original](assets/examples/watermark_original.png) | âœ… Detected |


---

#### ğŸ–¼ï¸ Slightly edited (Minor retouching or filters)
| Original | Detection |
|:--------:|:---------:|
| ![Original](assets/examples/edited_original.png) | âœ… Detected |

---

### Why It Matters

| Use Case | Benefit |
|----------|---------|
| **Storage Optimization** | Eliminating redundant copies to save petabytes of cloud storage |
| **Spam & Integrity** | Preventing "repost bots" from flooding feeds and protecting original creators from copyright infringement |
| **Search Relevance** | Ensuring a news aggregator doesn't show the same thumbnail ten times for one story |

---

## ğŸ’¡ Solution Overview

DejaView implements a **multi-layered detection pipeline** that combines:

1. **Perceptual Hashing (pHash)** â€” Fast structural fingerprinting
2. **Wavelet Hashing (wHash)** â€” Frequency-domain analysis for robustness
3. **CLIP Embeddings** â€” Deep semantic understanding via vision transformers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DejaView Pipeline                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   Input Image â”€â”€â–º pHash Check â”€â”€â–º wHash Check â”€â”€â–º CLIP Check    â”‚
â”‚                        â”‚              â”‚              â”‚          â”‚
â”‚                        â–¼              â–¼              â–¼          â”‚
â”‚                   [Duplicate]    [Similar]      [Similar]       â”‚
â”‚                    (Fast)        (Medium)       (Semantic)      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ System Architecture

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ Input Layer"]
        UI[Streamlit UI]
        API[ndid_model.py]
    end

    subgraph Core["âš™ï¸ Core Processing"]
        DC[duplicate_checker.py]
        
        subgraph Hashing["ğŸ” Perceptual Hashing (Linear)"]
            direction TB
            PH[pHash Check]
            WH[wHash Check]
        end
        
        subgraph Semantic["ğŸ§  Semantic Analysis"]
            CLIP[CLIP Embedding]
        end
    end

    subgraph Storage["ğŸ’¾ Vector Storage"]
        subgraph FAISS["FAISS Indices"]
            PI[(phash.index)]
            WI[(whash.index)]
            CI[(clip_index.index)]
        end
        
        subgraph Paths["Image Mappings"]
            HP[image_paths.npy]
            CP[clip_image_paths.npy]
        end
    end

    subgraph Models["ğŸ¤– AI Models"]
        ModelCheck{Local Available?}
        LM[Local CLIP Model]
        OM[OpenAI CLIP ViT-B/32]
    end

    %% Flow Connections
    UI --> API
    API --> DC
    
    %% Linear Processing Flow
    DC --> PH
    PH --> WH
    WH --> CLIP
    
    %% Storage Lookups
    PH <--> PI
    WH <--> WI
    CLIP <--> CI
    
    %% Path Retrievals
    PI --> HP
    WI --> HP
    CI --> CP
    
    %% Model Loading Logic
    CLIP --> ModelCheck
    ModelCheck -->|Yes| LM
    ModelCheck -->|No / Fallback| OM
```

---

## ğŸ”„ Pipeline Workflow

### Phase 1: Preprocessing & Indexing (Offline)

```mermaid
flowchart LR
    subgraph Preprocessing
        A[Raw Images] --> B[Image Validation]
        B --> C[EXIF Transpose]
        C --> D[RGB Conversion]
        D --> E[Preprocessed Images]
    end
    
    subgraph Hashing
        E --> F[Compute pHash]
        E --> G[Compute wHash]
        F --> H[Binary FAISS Index]
        G --> I[Binary FAISS Index]
    end
    
    subgraph CLIP_Indexing
        E --> J[CLIP Embedding]
        J --> K[L2 Normalize]
        K --> L[Inner Product Index]
    end
    
    H --> M[(phash.index)]
    I --> N[(whash.index)]
    L --> O[(clip_index.index)]
```

### Phase 2: Query & Detection (Online)

```mermaid
flowchart TD
    A[Upload Image] --> B{pHash Match?}
    B -->|Distance â‰¤ 4| C[âœ… DUPLICATE/SIMILAR]
    B -->|No| D{wHash Match?}
    
    D -->|Distance â‰¤ 4| E[âœ… SIMILAR]
    D -->|No| LoadModels
    
    subgraph LoadModels["ğŸ¤– Model Loading"]
        direction TB
        Check{Local Model?}
        Local[Load Local CLIP]
        Online[Load OpenAI CLIP]
        
        Check -->|Available| Local
        Check -->|Missing| Online
    end

    LoadModels --> F{CLIP Match?}
    
    F -->|Score â‰¥ 0.74| G[âœ… SIMILAR]
    F -->|No| H[âŒ UNIQUE]
    
    C --> I[Return Result]
    E --> I
    G --> I
    H --> I
    
    I --> J[Display in UI]
```

---

## ğŸ“ Project Structure

```
DejaView/
â”‚
â”œâ”€â”€ ğŸ“„ streamlitUI.py          # Web interface for image upload & results
â”œâ”€â”€ ğŸ“„ ndid_model.py           # Bridge between UI and detection pipeline
â”œâ”€â”€ ğŸ“„ duplicate_checker.py    # Core detection logic with 3-stage pipeline
â”‚
â”œâ”€â”€ ğŸ“„ Final_preprocessing_hashing.py  # Image preprocessing & hash generation
â”œâ”€â”€ ğŸ“„ Faiss_implementation.py         # FAISS index creation for hashes
â”œâ”€â”€ ğŸ“„ clip_train.py                   # CLIP embedding & indexing
â”œâ”€â”€ ğŸ“„ download_model.py               # Download CLIP model for local use
â”‚
â”œâ”€â”€ ğŸ“„ phash.index             # FAISS binary index for perceptual hashes
â”œâ”€â”€ ğŸ“„ whash.index             # FAISS binary index for wavelet hashes
â”œâ”€â”€ ğŸ“„ image_paths.npy         # Image path mappings for hash indices
â”‚
â”œâ”€â”€ ğŸ“‚ CLIP/
â”‚   â”œâ”€â”€ clip_index.index       # FAISS index for CLIP embeddings
â”‚   â”œâ”€â”€ clip_image_paths.npy   # Image path mappings for CLIP
â”‚   â””â”€â”€ clip_embeddings.npy    # Stored CLIP embeddings
â”‚
â”œâ”€â”€ ğŸ“‚ local_clip_model/       # Cached CLIP model (ViT-B/32)
â”œâ”€â”€ ğŸ“‚ images/                 # Dataset images
â”‚
â””â”€â”€ ğŸ“„ requirements.txt        # Python dependencies
```

### Module Descriptions

| Module | Purpose |
|--------|---------|
| `streamlitUI.py` | Interactive web UI for uploading images and viewing detection results |
| `ndid_model.py` | Handles file upload, creates temp files, and invokes the detection pipeline |
| `duplicate_checker.py` | Main orchestrator: loads indices, runs 3-stage detection (pHash â†’ wHash â†’ CLIP) |
| `Final_preprocessing_hashing.py` | Image preprocessing (EXIF, RGB) and perceptual/wavelet hash computation |
| `Faiss_implementation.py` | Builds FAISS binary indices from hash values |
| `clip_train.py` | Generates CLIP embeddings and builds semantic search index |
| `download_model.py` | Downloads and caches OpenAI CLIP model locally |

---

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.8+
- pip or conda

### Steps

```bash
# 1. Clone the repository
git clone https://github.com/your-username/DejaView.git
cd DejaView

# 2. Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate   # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Download CLIP model (one-time)
python download_model.py
```

### Dependencies

```
imagehash        # Perceptual & wavelet hashing
faiss-cpu        # Vector similarity search
numpy            # Numerical operations
Pillow           # Image processing
transformers     # CLIP model loading
torch            # Deep learning backend
streamlit        # Web UI framework
```

---

## ğŸš€ Usage

### Running the Web Interface

```bash
streamlit run streamlitUI.py
```

This will launch a local web server (typically at `http://localhost:8501`) where you can:

1. **Upload an image** (JPG, PNG, BMP supported)
2. **Click "Run NDID"** to analyze
3. **View results**: Status, similarity percentage, method used, and matched image

### Programmatic Usage

```python
from duplicate_checker import check_image_pipeline

result = check_image_pipeline("path/to/your/image.jpg")

print(result)
# {
#     "status": "Similar",           # Unique | Similar | Duplicate
#     "similarity_percentage": 87.5,
#     "matched_image_path": "/path/to/matched_image.png",
#     "source_image_path": "path/to/your/image.jpg",
#     "method": "clip"               # phash | whash | clip
# }
```

---

## ğŸ”¬ Technical Details

### Detection Thresholds

| Method | Threshold | Metric | Description |
|--------|-----------|--------|-------------|
| **pHash** | â‰¤ 4 bits | Hamming Distance | 64-bit hash, max 4 bit difference |
| **wHash** | â‰¤ 4 bits | Hamming Distance | 64-bit hash, max 4 bit difference |
| **CLIP** | â‰¥ 0.74 | Cosine Similarity | 512-dim embeddings, inner product |

### Why This Order?

```
pHash (Fastest)  â†’  wHash (Fast)  â†’  CLIP (Slowest but Smartest)
     â”‚                  â”‚                    â”‚
     â–¼                  â–¼                    â–¼
 ~0.1ms/img         ~0.2ms/img           ~50ms/img
```

1. **pHash first**: Catches exact/near-exact duplicates instantly
2. **wHash second**: Catches slight geometric transformations
3. **CLIP last**: Semantic understanding for edited/filtered images

### CLIP Model

- **Architecture**: ViT-B/32 (Vision Transformer, patch size 32)
- **Embedding Dimension**: 512
- **Source**: OpenAI CLIP via HuggingFace Transformers
- **Local Caching**: Model cached in `local_clip_model/` for offline use

### FAISS Index Types

| Index | Type | Use Case |
|-------|------|----------|
| `phash.index` | `IndexBinaryFlat` | Exact Hamming distance search |
| `whash.index` | `IndexBinaryFlat` | Exact Hamming distance search |
| `clip_index.index` | `IndexFlatIP` | Inner product (cosine) search |

---

## ğŸ“Š Evaluation Metrics

The system is evaluated using the **F1 Score**, which balances precision and recall:

```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```

| Metric | Definition |
|--------|------------|
| **Precision** | Of all detected duplicates, how many are actually duplicates? |
| **Recall** | Of all actual duplicates, how many did we detect? |
| **F1 Score** | Harmonic mean of precision and recall |

---

## ğŸ“š Datasets

### Recommended Datasets

| Dataset | Description | Link |
|---------|-------------|------|
| **Google Landmarks V2** | 5M+ landmark images with near-duplicates | [GitHub](https://github.com/cvdfoundation/google-landmark) |
| **INRIA Copydays** | Benchmark for copy detection with distortions | [INRIA](https://thoth.inrialpes.fr/~jegou/data.php.html#copydays) |

---

## ğŸ›ï¸ Architecture Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DejaView System                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Frontend  â”‚     â”‚              Backend Pipeline                    â”‚  â”‚
â”‚  â”‚             â”‚     â”‚                                                  â”‚  â”‚
â”‚  â”‚  Streamlit  â”‚â”€â”€â”€â”€â–¶â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚     UI      â”‚     â”‚  â”‚  pHash  â”‚â”€â”€â–¶â”‚  wHash  â”‚â”€â”€â–¶â”‚     CLIP      â”‚  â”‚  â”‚
â”‚  â”‚             â”‚     â”‚  â”‚  Check  â”‚   â”‚  Check  â”‚   â”‚  Embeddings   â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚                      â”‚       â”‚             â”‚                â”‚          â”‚  â”‚
â”‚                      â”‚       â–¼             â–¼                â–¼          â”‚  â”‚
â”‚                      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚                      â”‚  â”‚           FAISS Vector Store            â”‚    â”‚  â”‚
â”‚                      â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â”‚
â”‚                      â”‚  â”‚  â”‚ phash   â”‚ â”‚ whash   â”‚ â”‚   clip    â”‚  â”‚    â”‚  â”‚
â”‚                      â”‚  â”‚  â”‚ .index  â”‚ â”‚ .index  â”‚ â”‚  .index   â”‚  â”‚    â”‚  â”‚
â”‚                      â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â”‚
â”‚                      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ‘¥ Authors

Built with â¤ï¸ as part of the NDID (Near-Duplicate Image Detection) project.

---

## ğŸ“œ License

This project is for educational purposes.

---

## ğŸ¬ Project Demo

<p align="center">
  <a href="https://www.youtube.com/watch?v=YOUR_VIDEO_ID">
    <img src="https://img.shields.io/badge/YouTube-Watch%20Demo-red?style=for-the-badge&logo=youtube&logoColor=white" alt="Watch Demo on YouTube">
  </a>
</p>

â–¶ï¸ **[Click here to watch the full project demonstration](https://www.youtube.com/watch?v=YOUR_VIDEO_ID)**

<!-- REPLACE YOUR_VIDEO_ID with your actual YouTube video ID -->

---

<p align="center">
  <i>"Through the veil of Maya, DejaView sees the truth."</i>
</p>
